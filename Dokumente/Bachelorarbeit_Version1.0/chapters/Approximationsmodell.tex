% Main chapter 5:
% Approximationsmodell



\chapter{Approximationsalgorithmus}
\label{chap:Approximationsalgorithmus}

Das Kapitel \ref{chap:Approximationsalgorithmus} (Approximationsalgorithmus) stellt einen Algorithmus vor, mithilfe dessen aus einem Testdatensatz neue Fälle approximiert und zum Testdatensatz adaptiert werden können. Diese Verdichtung der Datenpunkte könnte man später als Grundlage für eine Regression nutzen, um so das Prognosemodell aus Kapitel \ref{chap:Modell} (Prognosemodell) mit echten, gemessenen Daten zu validieren und zu einem ganzheitlichen Modell zu vereinigen.




\section{Ansatz}
\label{sec:Ansatz}
In Kapitel \ref{chap:Modell} (Prognosemodell) wurde ein Prognosemodell für die mechanischen Eigenschaften (Flächenträgheitsmoment, Biege- und Torsionssteifigkeit) von Kabelbündeln erarbeitet. Dieses Modell wurde in Kapitel \ref{chap:Validierung} (Validierung) soweit validiert, dass für alle mechanischen Eigenschaften ein Korridor gefunden wurde welcher eine obere und untere Grenze für die realen mechanischen Eigenschaften darstellt. \\
\parskip 12pt \\
Unabhängig von theoretischen Modellen können Messungen durchgeführt werden um Informationen über reale Zusammenhänge zu erlangen. Eine wichtige Aufgabe liegt darin die vorhandenen Messdaten sinnvoll zu nutzen und einzusetzen. Es besteht die Möglichkeit innerhalb der Messwerte einen funktionalen Zusammenhang zur Beschreibung der mechanischen Eigenschaften zu finden. Gelingt dies, existiert sowohl die exakte (reale) Beschreibung des Problems basierend auf realen Messwerten, sowie die mathematische und mechanische Beschreibung in Form des theoretischen Prognosemodells, vereint in einem ganzheitlichen Modell. Die Messwerte führen auf einen Kopplungsfaktor (Fudge factor). Dadurch kann der Korridor auf eine einzelne Funktion reduziert werden. Gelingt dies, liegt ein Modell vor, welches sowohl die theoretisch korrekten Formeln sowie auch die real auftretenden Effekte beinhaltet. Um diese Vereinigung durchzuführen wird ein Set an Messdaten benötigt.\\
\parskip 12pt \\
Um funktionale Zusammenhänge in den Messdaten zu finden, kann grundsätzlich eine Regression durchgeführt werden. Hierbei wird jedoch nur sehr unspezifisch auf das Problem eingegangen. Mithilfe von Dimensionsanalyse und der Technik des Fallbasierten Schließens können die Problemeigenschaften sehr genau berücksichtigt werden und helfen, das Ergebnis der Approximation stark zu verbessern.\\
\parskip 12pt \\
Die Dimensionsanalyse reduziert den Lösungsraum von $n$ (Anzahl der Problemvariablen) auf $m$ (Anzahl dimensionslose Kennzahlen) Dimensionen. Somit entsteht eine Verdichtung der Messwerte. Es werden weniger Messwerte benötigt um die qualitativ gleichwertige Approximation durchzuführen. Das Fallbasierte Schließen nutzt ein vorhandenes Set von Mess- bzw. Trainingsdaten um neue Fälle zu adaptieren. Hierbei werden im Trainingsdatensatz ähnliche Fälle zum zu adaptierenden Fall gesucht. Dies geschieht über das Ähnlichkeitsmaß (siehe \cite{LSB06} und \cite{Her04}). Es kann hierbei eine weitere Eigenschaft der Dimensionsanalyse ausgenutzt werden.\\
\parskip 12pt \\
Wie in \cite{RH98a} und \cite{Rud02} beschrieben, stellen die dimensionslosen Kennzahlen die Bewertungseigenschaften eines Falles dar. Da sich die dimensionslosen Kennzahlen aus den physikalischen Eigenschaften ergeben, sind diese nicht frei wählbar und führen somit auf eine objektive Bewertung. Um das Ähnlichkeitsmaß zu bestimmen, wird der Unterschied ($\delta$ Variablenwert) zwischen Trainingsfall und zu adaptierendem Fall in jeder Eigenschaft (Variable) bestimmt. Da jede Eigenschaft eine eigene Dimension darstellt, wird faktisch das euklidische Distanzmaß als Ähnlichkeitsmaß genutzt. Alle Eigenschaften sind gleich gewichtet (jede andere Gewichtung wäre eine rein subjektive Entscheidung), daher ist die Inverse Distanzgewichtung die korrekte Methode um die Ähnlichkeit von Punkten im Pi-Raum zu ermitteln.\\
\parskip 12pt \\
Das Fallbasierte Schließen (siehe Unterabschnitt \ref{subsec:fallbasiertes-schliessen}) approximiert neue Fälle basierend auf den existierenden Testfällen. Da das euklidische Distanzmaß genutzt wird, kann zur Ermittlung der besten (ähnlichsten) Testpunkte eine Voronoi Diskretisierung genutzt werden (siehe Unterabschnitt \ref{subsec:Voronoi}). Hierbei wird der Raum in Gebiete nächster Nachbarn zerlegt. Der zu adaptierende Fall liegt in einem Gebiet. Dieses Gebiet ist einem Punkt zugeordnet, welches aufgrund der Konstruktion des Verfahrens der nächste Nachbar zum zu adaptierenden Fall ist. Würde man nur auf dem nächsten Nachbarn basierend approximieren, würde faktisch eine Klassifizierung stattfinden. Es werden daher weiter Punkte benötigt. Es zeigt sich, dass die $k$ nächsten Testpunkte nicht zwingend die besten Approximationspunkte sind. Um zwischen Punkten zu mitteln, müssen diese den zu optimierenden Punkt geometrisch umschließen. Dies ist für die $k$ nächsten Nachbarn nicht gegeben. Eine Approximation mit den $k$ nächsten Nachbarn führt auf hinreichend falsche Ergebnisse\\
\parskip 12pt \\
Mit der Technik der Delauny Triangulation (siehe Unterabschnitt \ref{subsec:Delauny}) werden die drei Punkte im $\mathbb{R}^2$ (Im $\mathbb{R}^3$ äquivalent vier Punkte und Tetraeder)  gefunden, welche das Dreieck aufspannen, die den zu adaptierenden Punkt minimal umschließen. Aus den drei Punkten kann mithilfe der Inversen Distanzgewichtung (siehe Unterabschnitt \ref{subsec:inversedist}) der neue Punkt approximiert und zur Falldatenbank hinzugefügt werden. (Falls mehr als drei Punkte zur Approximation genutzt werden sollen, kann das Verfahren auf die Nachbardreiecke der Delauny Triangulation erweitert werden. Dies Erweiterung wird hier nicht durchgeführt, soll aber als mögliche Verbesserung angesprochen werden.(siehe Unterabschnitt \ref{subsec:mehrpunkte}))\\
\parskip 12pt \\
Im folgenden soll nun ein Approximationsalgorithmus entwickelt werden, welches das Problem in den dimensionslosen Raum überführt und aus dem gegebenen Set an Testdaten über einen Fallbasierten Schließmechanismus (CBR) neue Fälle adaptiert. Diese Verdichtung der Testdaten kann dann genutzt werden um funktionale Zusammenhänge zu finden und schlussendlich das theoretische Prognosemodell mit den realen Messdaten zu vereinen. Dieses vereinte Modell basiert zum einen auf den theoretischen physikalischen und mechanischen Grundlagen und problemrelevanten Eigenschaften und berücksichtigt zudem die realen Messwerte und beobachteten Zusammenhänge.

\section{Algorithmus}
\label{sec:Algorithmus}

Im folgenden soll der Approximationsalgorithmus vorgestellt werden. Der Code wurde in Matlab2015a implementiert. Für die Validierung des Modells ist die Performance in Matlab ausreichend. Bei großen Datensets wird dies nicht mehr gegeben sein. Es wird daher empfohlen in anderen, problemspezifischen Umgebungen zu arbeiten. \\
\parskip 12pt \\
Der Pseudocode zeigt das Modell für den Validierungsfall. Es liegt kein Testdatenset vor, sondern dieses wird künstlich erzeugt. Die Validierungs- und Approximationsfälle werden ebenfalls künstlich erzeugt. Diese Methode eignet sich um die Güte und den Fehler des Modells zu ermitteln. Für reale Anwendungen muss der Code insofern abgeändert werden, dass es in diesem Fall keine Erzeugung von Testfällen gibt. Die Fehlerberechnung entfällt aufgrund nicht vorhandener Validierungsfälle.\\
\parskip 12pt \\
Die Input-Variablen geben die Zahl der Trainings- und Approximationspunkte vor. Die Größe der Arrays für die physikalischen Variablen und dimensionslosen Kennzahlen werden manuell angegeben. Das Modell kann in sofern erweitert werden, dass die Dimensionsanalyse automatisiert abläuft. In diesem Fall liegen die Informationen für die Arraygröße ohne Eingabe direkt vor.

\begin{table}[H]
\centering % centering table
\begin{tabular}{|l|l|l|}
\hline \hline
\multicolumn{3}{|l|}{input variables}                                      \\ \hline
\multirow{9}{*}{}  & \multicolumn{2}{l|}{set variables}                   \\ \cline{2-3} 
                   & \multicolumn{2}{l|}{\multirow{5}{*}{}} \\
                   & \multicolumn{2}{l|}{n - number of physical variables}                     \\
                   & \multicolumn{2}{l|}{d - number of dimensions ($\Pi$'s)}                     \\
                   & \multicolumn{2}{l|}{m - number of test cases}                     \\
                   & \multicolumn{2}{l|}{k - number of approximation cases}                     \\
                   & \multicolumn{2}{l|}{}                     \\ \cline{2-3} 
\hline
\end{tabular}
\caption{Algorithmus - Eingabevariablen} %title of the table
\label{tab:algInp}
\end{table} 

Es werden zufällige Trainingsdaten erstellt wobei die letzte Variable und die dimensionslosen Kennzahlen errechnet werden. Des weiteren werden die Validierungsfälle nach dem selben Prinzip erstellt. Die Approximationsfälle entstehen aus den Validierungsfällen wobei die letzte Variable und das letzte $Pi$ nicht übernommen werden.
\begin{table}[H]
\centering % centering table
\begin{tabular}{|l|l|l|}
\hline \hline
\multicolumn{3}{|l|}{generate data}                                      \\ \hline
\multirow{9}{*}{}  & \multicolumn{2}{l|}{generate test cases}                   \\ \cline{2-3} 
                   & \multicolumn{2}{l|}{\multirow{6}{*}{}} \\
                   & \multicolumn{2}{l|}{for i = 1:1:n}                     \\
                   & \multicolumn{2}{l|}{\hspace{5 mm}generate random values for $variable_1$ to $variable_{n-1}$}                     \\
                   & \multicolumn{2}{l|}{\hspace{5 mm}calculate $variable_n$}                     \\
                   & \multicolumn{2}{l|}{\hspace{5 mm}calculate $\Pi_1$ to $\Pi_m$}                     \\
                   & \multicolumn{2}{l|}{end}					     \\ \cline{2-3} 
                   & \multicolumn{2}{l|}{}                     \\ \cline{2-3} 
                   & \multicolumn{2}{l|}{generate validation cases}                     \\ \cline{2-3} 
                   & \multicolumn{2}{l|}{\multirow{5}{*}{}} \\
                   & \multicolumn{2}{l|}{for i = 1:1:k}                     \\ 
                   & \multicolumn{2}{l|}{\hspace{5 mm}generate random values for $variable_1$ to $variable_{n-1}$}                     \\
                   & \multicolumn{2}{l|}{\hspace{5 mm}calculate $variable_n$}                     \\
                   & \multicolumn{2}{l|}{\hspace{5 mm}calculate $\Pi_1$ to $\Pi_m$}                     \\
                   & \multicolumn{2}{l|}{end}                     \\ \cline{2-3} 
                   & \multicolumn{2}{l|}{}                  \\ \cline{2-3} 
                                      & \multicolumn{2}{l|}{generate approximation cases}                     \\ \cline{2-3} 
                   & \multicolumn{2}{l|}{\multirow{4}{*}{}} \\
                   & \multicolumn{2}{l|}{for i = 1:1:k}                     \\ 
                   & \multicolumn{2}{l|}{\hspace{5 mm}copy $variable_1$ to $variable_{n-1}$ from validation}                     \\
                   & \multicolumn{2}{l|}{\hspace{5 mm}copy $\Pi_1$ to $\Pi_{m}$ from validation}                     \\
                   & \multicolumn{2}{l|}{end}                     \\ \cline{2-3} 
\hline
\end{tabular}
\caption{Algorithmus - Datengenerierung} %title of the table
\label{tab:algGenerate}
\end{table} 


Basierend auf den Trainingsfällen wird der Raum mit einer Delauny Triangulation diskretisiert. Daraus kann als komplementär die Voronoi Zerlegung abgeleitet werden. Über die Delauny Triangulation wird später das beste Dreieck zum Approximieren ausgewählt. 
\begin{table}[H]
\centering % centering table
\begin{tabular}{|l|l|l|}
\hline \hline
\multicolumn{3}{|l|}{discretization}                                      \\ \hline
\multirow{9}{*}{}  & \multicolumn{2}{l|}{space discretization}                   \\ \cline{2-3} 
                   & \multicolumn{2}{l|}{\multirow{6}{*}{}} \\
                   & \multicolumn{2}{l|}{dt delauny triangulation ($\Pi_2$ to $\Pi_m$)}                     \\
                   & \multicolumn{2}{l|}{va voronoi areas ($\Pi_2$ to $\Pi_m$)}                     \\
                   & \multicolumn{2}{l|}{for i = 1:1:k}                     \\
                   & \multicolumn{2}{l|}{\hspace{5 mm}delete approximation case if not element of one triangle of dt}                    \\
                    & \multicolumn{2}{l|}{\hspace{5 mm}(point is at the far side and can't be approximated)}                      \\
                    & \multicolumn{2}{l|}{end}                      \\ \cline{2-3} 
\hline
\end{tabular}
\caption{Algorithmus - Diskretisierung} %title of the table
\label{tab:algRaum}
\end{table}

Die Approximation erfolgt über das euklidische Distanzmaß. Zuerst wird die Distanz jedes Punkts des Dreiecks bestimmt, hieraus entsteht das Gewichtungsmaß als Reziproke der Distanz. Die Funktionswerte der Punkte des ausgewählten Dreiecks werden mit den Gewichtungsfaktoren verrechnet und so der fehlende Wert approximiert. Dieser Programmteil stellt das Kernstück des Approximationsalgorithmus dar. Die Wahl des Gewichtungsverfahrens ist opportunistisch und kann mit Begründung auch geändert werden.
\begin{table}[H]
\centering % centering table
\begin{tabular}{|l|l|l|}
\hline \hline
\multicolumn{3}{|l|}{approximate}                                      \\ \hline
\multirow{9}{*}{}  & \multicolumn{2}{l|}{euclidean distance}                   \\ \cline{2-3} 
                   & \multicolumn{2}{l|}{\multirow{5}{*}{}} \\
                   & \multicolumn{2}{l|}{for i = 1:1:k}                     \\
                   & \multicolumn{2}{l|}{\hspace{5 mm}calculate euclidean distance (approximation case to dt($\Pi_1$ to $\Pi_d$)}                     \\
                   & \multicolumn{2}{l|}{\hspace{5 mm}calculate inverse distance weight for dt($\Pi_1$ to $\Pi_d$)}                     \\
                   
                   & \multicolumn{2}{l|}{end}					     \\ \cline{2-3} 
                   & \multicolumn{2}{l|}{}                     \\ \cline{2-3} 
                   & \multicolumn{2}{l|}{calculate value}                     \\ \cline{2-3} 
                   
				& \multicolumn{2}{l|}{\multirow{8}{*}{}} \\
                   & \multicolumn{2}{l|}{for i = 1:1:k}                     \\ 
                   & \multicolumn{2}{l|}{\hspace{5 mm}for j = i:1:d}                     \\
                   & \multicolumn{2}{l|}{\hspace{10 mm}calculate euclidean distance (approximation case to dt($\Pi_1$ to $\Pi_d$)}                     \\
                   & \multicolumn{2}{l|}{\hspace{10 mm}calculate inverse distance weight for dt($\Pi_1$ to $\Pi_d$)}                     \\
                   & \multicolumn{2}{l|}{\hspace{5 mm}end}                     \\
                   & \multicolumn{2}{l|}{\hspace{5 mm} approximation case $\Pi_1$ = $\frac{\sum \Pi_{1_i} weight_i}{\sum weight_i}$  }                    \\
                   & \multicolumn{2}{l|}{end}                     \\ \cline{2-3}                                      
                   
\hline
\end{tabular}
\caption{Algorithmus - Approximation} %title of the table
\label{tab:algapprox}
\end{table} 




Es wird der Fehler des approximierten Wertes für die dimensionslose Kennzahl und die physikalische Variable mit Hilfe des Validierungsfalls berechnet.
\begin{table}[H]
\centering % centering table
\begin{tabular}{|l|l|l|}
\hline \hline
\multicolumn{3}{|l|}{validation}                                      \\ \hline
\multirow{9}{*}{}  & \multicolumn{2}{l|}{error}                   \\ \cline{2-3} 
                   & \multicolumn{2}{l|}{\multirow{4}{*}{}} \\
                   & \multicolumn{2}{l|}{for i = 1:1:k}                     \\
                   & \multicolumn{2}{l|}{\hspace{5 mm}calculate error approximation case $\Pi_1$}                    \\
                    & \multicolumn{2}{l|}{\hspace{5 mm}calculate error approximation case $variable_1$}                      \\
                    & \multicolumn{2}{l|}{end}                        \\ \cline{2-3} 
\hline
\end{tabular}
\caption{Algorithmus - Validierung} %title of the table
\label{tab:algVal}
\end{table}





Es werden drei Plots dargestellt. Zum einen die Raumdiskretisierung mit Delauny Triangulation und Voronoi Gebieten. Außerdem die Darstellung der Trainings-, Validierungs- und Approximationsfälle sowie der Delauny Dreiecke für die Approximation. Der dritte Plot stellt den Fehler der approximierten Fälle dar.
\begin{table}[H]
\centering % centering table
\begin{tabular}{|l|l|l|}
\hline \hline
\multicolumn{3}{|l|}{plot}                                      \\ \hline
\multirow{9}{*}{}  & \multicolumn{2}{l|}{figure1: Raumdiskretisierung (2D if d = 3)}                   \\ \cline{2-3} 
                   & \multicolumn{2}{l|}{\multirow{5}{*}{}} \\
                   & \multicolumn{2}{l|}{plot dt delauny triangulation ($\Pi_2$ to $\Pi_d$)}                     \\
                   & \multicolumn{2}{l|}{plot va voronoi areas ($\Pi_2$ to $\Pi_d$)}                     \\
                   & \multicolumn{2}{l|}{plot approximation cases ($\Pi_2$ to $\Pi_d$)}                     \\
                   & \multicolumn{2}{l|}{mark triangles for approximation cases}                     \\ \cline{2-3} 
                   & \multicolumn{2}{l|}{}                     \\ \cline{2-3} 
                   & \multicolumn{2}{l|}{figure2: test-,validate- and approximate cases (2D if d = 3)}                     \\ \cline{2-3} 
                   & \multicolumn{2}{l|}{\multirow{5}{*}{}} \\
                   & \multicolumn{2}{l|}{plot test cases ($\Pi_1$ to $\Pi_d$)}                     \\ 
                   & \multicolumn{2}{l|}{plot validation cases ($\Pi_1$ to $\Pi_d$)}                     \\
                   & \multicolumn{2}{l|}{plot approximation cases ($\Pi_1$ to $\Pi_d$)}                     \\
                   & \multicolumn{2}{l|}{mark triangles for approximation cases}                       \\ \cline{2-3} 
                   & \multicolumn{2}{l|}{}                  \\ \cline{2-3} 
                                      & \multicolumn{2}{l|}{figure3: error plot (3D if d = 3)}                     \\ \cline{2-3} 
                   & \multicolumn{2}{l|}{\multirow{2}{*}{}} \\
                   & \multicolumn{2}{l|}{plot error ($\Pi_1$ to $\Pi_d$)}                                          \\ \cline{2-3} 
\hline
\end{tabular}
\caption{Algorithmus - Plot} %title of the table
\label{tab:algplot}
\end{table} 


\section{Anwendungsbeispiel - Stoßdämpfer}
\label{sec:anwendungBSP}
\subsection{Anforderungen}
\label{subsec:anforderungenBSP}
Um den Mechanismus des Approximationsalgorithmus vorzustellen, soll ein praktisches Beispiel genutzt werden. Die Anforderungen an den Anwendungsfall sind zum einen ein bekannter physikalischer Zusammenhang und zum anderen eine Reduktion des Lösungsraums auf $m = 3$ (drei dimensionslose Kennzahlen). Prinzipiell ist jedes Problem, auch $m \neq 3$ möglich, jedoch lässt sich das Problem mit $m = 3$ noch visuell darstellen und ist trotzdem hinreichend komplex. Im folgenden soll das Problem ``Stoßdämpfer - Eine schnell bewegte Masse trifft auf ein Hindernis`` vorgestellt werden.\\
\parskip 12pt \\
Das gewählte Problem ist aus \cite{Her04} übernommen und wird dort aus \cite{Szi89} zitiert. Das Stoßdämpfer-Beispiel wurde aufgrund der oben genannten Anforderungen ausgewählt und steht in keinem physikalischen Zusammenhang zur Fragestellung der Eigenschaften von Kabelbündeln. Ziel ist es den Approximationsalgorithmus vorzustellen. Die physikalische Beschreibung, die Dimensionsanalyse und die dimensionslosen Kennzahlen werden daher aus \cite{Szi89} respektive \cite{Her04} übernommen. Alle weiteren Analysen basieren auf eigenen, über einen Zufallsgenerator erzeugten Zahlen und Testfällen und sind losgelöst von der Betrachtung in \cite{Her04}.

\subsection{physikalische Beschreibung}
\label{subsec:physBeschr}
Beim Stoßdämpfer-Problem trifft eine schnell bewegte Masse auf ein Hindernis. Der Stoßdämpfer reduziert die Aufschlagskraft der Masse.
\begin{figure}[h]
	\centering
		\includegraphics[width=1\textwidth]{images/daempfer.jpg}
	\caption[Anwendung - Beispiel: Stoßdämpfer]{Anwendung - Beispiel: Stoßdämpfer \cite{Szi89}}
	\label{fig:daempfer}
\end{figure}
 Die bewegte $Masse[kg]$ mit der Geschwindigkeit $v_0[\frac{m}{s}]$ wird über den Stoßdämpfer mit Federkonstante $c_1[\frac{kg}{s^2}]$ gebremst. Die Kompression der Feder ist gegeben durch $\lambda[m]$. Die Struktur wird ebenfalls als Feder betrachtet, mit Federkonstante $c_2[\frac{kg}{s^2}]$. Es wird angenommen, dass immer die maximale Aufschlagskraft $F[\frac{kg \cdot m}{s^2}]$ der Masse wirkt. 

 
\begin{table}[h]
\centering % centering table
\begin{tabular}{|c|c|c|} % creating eight columns
\hline\hline %inserting double-line
physikalische Variable & Symbol & Dimension  \\ 
\hline % inserts single-line
Aufschlagskraft & F & $\frac{kg \cdot m}{s^2}$ \\
Geschwindigkeit Masse & $v_0$ & $\frac{m}{s}$ \\
Federkonstante Stoßdämpfer & $c_1$ & $\frac{kg}{s^2}$\\
Federkonstante Struktur & $c_2$ & $\frac{kg}{s^2}$\\
lineare Kompression Stoßdämpfer & $\lambda$ & m \\
Masse & m & kg \\
\hline % inserts single-line
\end{tabular}
\label{tab:stoss}
\caption{Anwendung - Beispiel: Stoßdämpfer} %title of the table
\end{table}  
 

 
Das System ist konservativ, es findet kein Energiefluss über die Systemgrenzen statt. Die Deformation der Feder ist linear.

\subsection{Dimensionsanalyse}
\label{subsec:dimAnBsp}

Mit der in Unterabschnitt \ref{subsec:Pi} vorgestellten Methode werden aus den dimensionsbehafteten Größen ($F[\frac{kg\cdot m}{s^2}]$, $v_0[\frac{m}{s}]$, $c_1[\frac{kg}{s^2}]$, $c_2[\frac{kg}{s^2}]$, $\lambda[m]$, $Masse[kg]$) die dimensionslosen Kennzahlen ($\Pi_1, \Pi_2, \Pi_3$) gebildet. Mit dem funktionalen Zusammenhang aus Formel \eqref{f5b}, sowie $n = 6$ und $r = 3$ ergibt sich $m = 3$. Speziell ergeben sich die folgenden Kennzahlen:

\begin{equation}\label{f69}
\Pi_1 = \frac{F}{c_2 d}
\end{equation}
\begin{equation}\label{f70}
\Pi_2 = \frac{v_0}{\lambda}\sqrt{\frac{M}{c_2}}
\end{equation}
\begin{equation}\label{f71}
\Pi_3 = \frac{c_1}{c_2} 
\end{equation}
Aus dem allgemeinen physikalischen Zusammenhang
\begin{equation}\label{f72}
F = \sqrt{c_2(M v_0^2-c_1 \lambda^2)}
\end{equation}
ergibt sich der dimensionslose Zusammenhang der Pi's (siehe Abbildung \ref{fig:piDat})
\begin{equation}\label{f73}
\Pi_1 = \sqrt{\Pi_2^2  - \Pi_3}
\end{equation}

\begin{figure}[h]
	\centering
		\includegraphics[width=1\textwidth]{images/flaeche-pi.jpg}
	\caption[Anwendung - Graph im dimensionslosen Raum]{Anwendung - Graph der Pi's im dimensionslosen Raum (Gleichung \eqref{f73})}
	\label{fig:piDat}
\end{figure}
\newpage
\subsection{Durchführung}
\label{subsec:durchBsp}

Ziel ist es für neue, unbekannte Fälle  (Vorgabe aller Variablen bis auf eine (hier $F$)) ohne das Wissen über den physikalischen Zusammenhang, die fehlende Variable $F$ zu approximieren. Hier werden im Modell für das Anwendungsproblem Testfälle erzeugt.\\ Es gibt hierbei drei Datensets:\begin{itemize}
\item Trainingsfälle: Die Variablen $v_0, c_1, c_2, \lambda, M$ werden als Zufallszahlen $x_i$ mit \\$x~=~\{x~\in~\mathbb{R}~|~0~\le~x~\leq 10\}$ erzeugt. F wird basierend darauf berechnet. Um sicherzustellen, dass F ebenfalls positiv ist, werden nur Fälle berücksichtigt bei denen $M v_0^2 > c_1 \lambda^2$ gilt. In realen Anwendungen werden die Trainingsfälle aus Messdaten gebildet.\\
\parskip 12pt \\
\item Validierungsfälle: Analog zu den Trainingsfällen werden Validierungsfälle erzeugt. Diese Fälle dienen im weiteren der Validierung der Approximationsfälle und zur Berechnung der Fehler. Bei realen Problemstellungen existieren diese Fälle nicht. Es können jedoch Trainingsfälle genutzt werden und als Validierungs- und Approximationsfälle genutzt werden um die Güte des Modells zu ermitteln und Informationen über den Fehler zu erhalten.
\item Approximationsfälle: Die zu approximierenden Fälle sind identisch mit den Approximationsfällen (identische Zahlenwerte für ($v_0, c_1, c_2, \lambda, M$)), allerdings  wird die fehlende Variable $F$ nicht berechnet sondern über das Modell approximiert. Anschließend können die approximierten Werte mit den Werten der Validierungsfälle verglichen werden um die Güte des Modells und den Fehler zu bestimmen. In realen Anwendungen sind Approximationsfälle die Fälle welche den Zugewinn an Wissen und Erkenntnis darstellen.
\end{itemize}



\section{Anwendung mit Testfall}
\label{sec:Anwendung Testfall}
Das in Abschnitt \ref{sec:anwendungBSP} vorgestellte Beispiel eines Stoßdämpfers wird nun genutzt um den in Abschnitt \ref{sec:Algorithmus} vorgestellten Approximationsalgorithmus in einer praktischen Anwendung zu zeigen. Es werden hierfür $m = 1000$ Trainings- sowie $k = 5$ Validierungsfälle genutzt. Für alle physikalischen Variablen ($n = 1$ bis $n_{ges}-1 = 5$) werden wie vorher beschrieben Zufallszahlen $x_i$ mit $x=\{x \in \mathbb{R} | 0 \le x \leq 10\} $ erzeugt. Es werden lediglich Fälle aussortiert bei denen $(M v_0^2 - c_1 \lambda^2)$ negativ ist, da in diesem Fall imaginäre Kräfte entstehen würden.\\
\parskip 12pt \\
Tabelle \ref{tab:anwDatdimbe} zeigt die fünf zufällig erzeugten Testfälle in dimensionsbehafteten Variablen. Die Variable F soll über das Verfahren approximiert werden. Zusätzlich enthält Tabelle \ref{tab:anwDatdimbe} die dimensionsbehafteten Variablen für die drei jeweils zur Approximation benutzten Trainingspunkte. (Es liegen die Variablen für alle $m = 1000$ Trainingspunkte vor, aus Gründen der Übersicht wird hier auf die spätere Auswahl der Trainingspunkte vorgegriffen.)

\begin{table}[H]
\centering % centering table
\scalebox{0.85}{
\begin{tabular}{|r|c|r|r|r|r|r|}
\hline\hline
\# & F & $v_0$ & $c_1$ & $c_2$ & $\lambda$ & M \\ \hline \hline
1        & ? &     0.3764  &  0.4531  &  3.0392  &  1.2020 & 124.7417    \\ \hline
   &      9.3526   & 7.1958  &  0.4772 &   8.6173  &  0.5030    &   0.1984    \\ \hline
   &     5.7139   & 3.7477  &  0.9574  &  3.7809   & 0.7605   &    0.6542   \\ \hline
   &        7.8536  &  3.0958  &  0.1640  &  1.6523   & 2.5623   &    4.0071   \\ \hline \hline
2  &  ? &      9.9932 &   5.1846  &  2.7251 &   3.1945   & 0.7837    \\ \hline
   &      7.2597  &  0.0651  &  7.8243  &  4.1417   & 1.8979 &   9661.6000          \\ \hline
   &      9.9857  &  0.2766  &  8.8869   & 4.7090   & 1.5533  &   557.0012      \\ \hline
   &        9.2959  &  3.3385   & 3.0252 &   1.3698   & 6.1769    &  16.0158   \\ \hline \hline
3  &   ?   &     1.2065  &  6.5139  &  1.3716 &   3.6574   & 68.3730    \\ \hline
   &         5.4779  &  4.8008  &  8.3612  &  1.9814   & 1.3633  &     1.3314   \\ \hline
   &     6.7962  &  0.6228 &   9.1909 &   1.8433   & 4.6881   &  585.3864    \\ \hline
   &   2.6456  &  9.3552   & 9.6888  &  2.1572   & 1.6193   &    0.3273 \\
\hline \hline
4  &     ? &     1.9613 &   0.5559 &   1.1878  &  1.6266  & 16.0034       \\ \hline
   &        4.7928 &   1.7165  &  0.5900  &  8.0707   & 0.1153   &    0.9687   \\ \hline
   &        6.6314  &  7.0918  &  5.8253  &  5.9962   & 0.2313   &    0.1520  \\ \hline
   &         9.3903  &  8.1846 &   4.0871 &   7.1609   & 0.3169   &    0.1899    \\
\hline \hline
5  &      ? &  0.0018 &  9.0307  &  3.6583  &  2.8787 & $2.4177 \cdot 10^7$       \\ \hline
   &          8.8362  &  4.4708  & 8.9423  &  3.5928   & 6.9438   &   22.6591   \\ \hline
   &         5.0640  &  9.2929  &  5.5282  &  2.2414   & 6.8714    &   3.1550  \\ \hline
   &         9.3722  &  2.9950  &  9.1107  &  3.6970   & 5.3263    &  31.4631   \\      
\hline
\end{tabular}}
\caption{Anwendung - Datenset (dimesionsbehaftet)} %title of the table
\label{tab:anwDatdimbe}
\end{table}

\begin{table}[H]
\centering % centering table
\scalebox{0.85}{
\begin{tabular}{|r|c|r|r|c|c|}
\hline\hline
\# & $\Pi_1$ & $\Pi_2$ & $\Pi_3$&  distance & weight \\ \hline \hline
1  & ?      &    2.0061  &  0.1491       & -        & -      \\ \hline
   &    2.1578 &   2.1706  &  0.0554     &  0.1893            &  5.2828      \\ \hline
   &    0.9236  &  1.6559  &  1.8891       &  0.1129            &  8.8547     \\ \hline
   &     2.0279 &   2.8866 &   4.2198       &  0.1342        &  7.4532      \\ \hline \hline
2  & ?      &       1.6776  &  1.9025       & -        &   -     \\ \hline
   &      5.1489 &   5.1560  &  0.0731   &  0.0255            &   39.2137         \\ \hline
   &      0.3542   & 1.6169   & 2.4890    &  0.2596            &    3.8520        \\ \hline
   &        1.9871 &   2.0499  &  0.2532     &  0.3503        &   2.8546     \\ \hline \hline
3  &  ?      &       2.3291 &   4.7490    &   -       &  -      \\ \hline
   &        1.3652 &   1.9368  &  1.8872    &  0.7687            &   1.3009         \\ \hline
   &       0.7864 &   2.3674 &   4.9860     &   0.2401           &    4.1647        \\ \hline
   &      4.7811  &  4.8816  &  0.9715      &   0.2694       &    3.7123    \\
\hline \hline
4  &   ?     &       4.4258  &  0.4680        &  -        & -       \\ \hline
   &       0.3288  &  1.6045  &  2.4664      &  0.8301            &   1.2047         \\ \hline
   &       1.8550  &  1.8816 &   0.0992     &  0.6792            &    1.4724        \\ \hline
   &       1.0987 &   1.8481   & 2.2085      &  0.2422        &   4.1281     \\
\hline \hline
5  &    ?    &        1.6096 &   2.4685      &    -      &   -     \\ \hline
   &        0.7574  &  2.2505   & 4.4913     &   0.0217           &  46.0380        \\ \hline
   &        4.1381  &  4.2065  &  0.5708   &  0.0055            &    182.9383       \\ \hline
   &        0.4760  &  1.6404  &  2.4644    &  0.0311        &   32.1721     \\      
\hline
\end{tabular}}
\caption{Anwendung - Datenset (dimesionslos)} %title of the table
\label{tab:anwDatdimlos}
\end{table}


Die dimensionslosen Kennzahlen $\Pi_1, \Pi_2, \Pi_3$ werden basierend auf den Formeln in Abschnitt \ref{sec:anwendungBSP} errechnet. Tabelle \ref{tab:anwDatdimlos} zeigt diese Größen sowie die Kennzahlen der Trainingspunkte welche die Grundlage der Approximation bilden. Diese Trainingsfälle werden Über die Delauny Triangulation zu den Approximationspunkten zugeordnet. Aus diesen wird über das euklidische Distanzmaß der fehlende Wert in $\Pi_1$ errechnet. Das vollständige Pi-Set kann dann zur Berechnung des fehlenden physikalischen Wertes $F$ genutzt werden.\\
\parskip 12pt \\
\begin{figure}[h]
	\centering
		\includegraphics[width=1\textwidth]{images/Datenmodell2legextra.jpg}
	\caption[Anwendung - Datenmodell]{Anwendung - Datenmodell}
	\label{fig:anwDatmod}
\end{figure}


Die graphische Darstellung der  zufällig erzeugten Punkte erfolgt in Abbildung \ref{fig:anwDatmod}. Hierbei werden die Trainings-, Validierungs- und approximierten Daten sowie die relevanten Dreiecke der Triangulation dargestellt. Die in Abbildung \ref{fig:piDat} dargestellte Oberfläche ist durch die Trainingspunkte in Abbildung \ref{fig:anwDatmod} ersichtlich.\\
\parskip 12pt \\
Aufgrund der Nutzung von Zufallszahlen für die Trainingspunkte, kommt es zu einer Ballung um den Punkt ($\Pi_2$ = 1 /$\Pi_3$ = 1) Dies hat jedoch keine negativen Auswirkungen. Die Abbildung \ref{fig:anwDatmod} zeigt die fünf approximierten Punkte mit dem jeweiligen Validierungspunkt (Kontrollpunkt über  Formelbeziehung gerechnet). Der Fehler der Approximation entspricht dem Unterschied von approximiertem Punkt und Validierungspunkt in $\Pi_1$-Koordinate. Die zur Approximation ausgewählten Trainingspunkte ergeben sich aus dem Delauny Dreieck.
\begin{figure}[h]
	\centering
		\includegraphics[width=1\textwidth]{images/Diskretisierung2leg.jpg}
	\caption[Anwendung - Diskretisierung]{Anwendung - Diskretisierung}
	\label{fig:anwDisk}
\end{figure}
Die Abbildung \ref{fig:anwDisk} zeigt die Diskretisierung über Delauny Triangulation und Voronoi Gebiete im 2D ($\Pi_2$ / $\Pi_3$). Die $\Pi_1$-Koordinate wird approximiert und ist daher für die Diskretisierung nicht relevant. In Abbildung \ref{fig:anwDisk} ist ebenfalls wieder die Ballung der Punkte um den Punkt {($\Pi_2$ = 1 / $\Pi_3$ = 1)} zu sehen. Die Delauny Triangulation ergibt hier eine sehr dichte Wolke. Auf der rechten Seite der Abbildung ist die Diskretisierung von Voronoi Gebieten und Delauny Triangulation anschaulich. Links zeigt sich, dass der Mangel an Punkten in einem Gebiet und eine ungünstige Verteilung zu sehr unschönen Voronoi Diskretisierungen führen können. Dies  ist besonders in Randgebieten oft der Fall. Aus der 2D-Diskretisierung können die vorher angesprochenen besten Delauny Dreiecke bestimmt werden. Für die zu approximierenden Werte sowie die besten Dreiecke, werden in Tabelle \ref{tab:anwDatdimbe} alle dimensionsbehafteten und in Tabelle \ref{tab:anwDatdimlos} alle dimensionslosen Größen dargestellt. Hierbei entspricht die erste Zeile dem zu approximierenden Wert und die drei folgenden Zeilen den drei Punkten des besten Dreiecks. Zusätzlich werden die Distanz und die daraus resultierende Gewichtung für die Approximation angegeben. Man beachte, dass das Gewicht $w$ reziprok zur Distanz $d$ ist.\\
\parskip 12pt \\
Aus den $\Pi_1$-Werten und den Gewichten der drei besten Punkte wird nach dem Prinzip der Inversen Distanzgewichtung (siehe Unterabschnitt \ref{subsec:inversedist}) der $\Pi_1$-Wert des zu approximierenden Punktes ermittelt. Um den ursprünglich gesuchten Wert F zu ermitteln müssen die Daten in den dimensionsbehafteten Raum rücktransformiert werden. Dabei ergibt sich der fehlende Wert. Auf die Rücktransformation soll hier verzichtet werden, das Prinzip wurde im Unterabschnitt \ref{subsec:Pi} vorgestellt. Die Fehlerauswertung für die fünf Approximationsfälle wird in Tabelle \ref{tab:anwFehler} gezeigt. Approximation und Validierung stimmen aufgrund der Methode in $\Pi_2$ und $\Pi_3$ exakt überein. Die Abweichung in $\Pi_1$ stellt den Fehler des Verfahrens dar. Dieser wird nach dem Prinzip der Gleichung \eqref{f68} berechnet.

\begin{table}[H]
\centering % centering table

\begin{tabular}{|r|l|l|l|c|}
\hline \hline
\#       & $\Pi_1$ & $\Pi_2$ & $\Pi_3$ & Err. $\Pi_1 [\%]$ \\ \hline \hline
App 1 &    1.9833  &  2.0061  &  0.1491    &     0.7448              \\ \hline
Val 1    &    1.9686  &  2.0061  &  0.1491    &       -        \\ \hline\hline
App 2 &      0.9715  &  1.6776  &  1.9025        &    1.7366           \\ \hline
Val 2    &        0.9549  &  1.6776  &  1.9025       &      -         \\ \hline \hline
App 3 &     0.9507  &  2.3291  &  4.7490       &    15.6601           \\ \hline
Val 3    &         0.8219  &  2.3291 &   4.7490       &       -        \\ \hline \hline
App 4 &      4.4561 &   4.4258   & 0.4680      &    1.9095           \\ \hline
Val 4    &        4.3726  &  4.4258  &  0.4680       &       -        \\ \hline \hline
App 5 &        0.3514 &   1.6096  &  2.4685        &    0.4888           \\ \hline
Val 5    &        0.3497  &  1.6096  &  2.4685        &       -        \\ \hline
\end{tabular}
\caption[Anwendung - Fehler]{Anwendung - Fehler $\Pi_1$} %title of the table
\label{tab:anwFehler}
\end{table}

Insgesamt kann mit diesem Datenset gezeigt werden, dass der Approximationsmechanismus funktioniert. Der Fehler liegt bei vier der fünf Fälle im Bereich $\le 2\%$. Lediglich Testfall 3 weist einen Fehler von $15\%$ auf Allerdings muss angemerkt werden, dass die erzeugten fünf Testfälle nicht repräsentativ sind und in diesem Fall ein sehr gutmütiges Fehlerverhalten vorliegt. Für große Datensets liegt der Fehler in der Regel für $90\%$ der Approximationspunkte bei $\le 10\%$. Dies soll jedoch nicht genau untersucht werden, da der absolute Approximationsfehler nur in Relation zu anderen Verfahren und Approximationsmethoden eine sinnvolle Aussage über die Güte des Verfahrens zulässt. Hier soll nur die prinzipielle Funktionsweise des Modells gezeigt werden. Außerdem wird klar, dass die approximierten Werte allgemein sinnvoll sind und das Verfahren korrekt funktioniert.

\section{Erweiterungen und Alternativen}
\label{sec:erweiterungen}

Die genutzten Approximationen wurde bisher aus exakt drei Punkten errechnet. Eine potenzielle Erweiterung besteht darin weitere Punkte einzubeziehen. Dies soll in Unterabschnitt \ref{subsec:mehrpunkte} diskutiert werden. Das gewichtete Distanzmaß wurde im Modell bisher aus opportunistischen Gründen genutzt. In Unterabschnitt \ref{subsec:gewichtung} soll diskutiert werden welche alternativen Gewichtungsfunktionen genutzt werden könnten.
\subsection{Zusätzliche Approximationspunkte}
\label{subsec:mehrpunkte}
Die bisher gewählten Punkte umschließen den zu approximierenden Punkt minimal. Es erscheint eventuell vorteilhafter zusätzliche Punkte ebenso nach dem Prinzip zu wählen, dass die Punkte den zu approximierenden Punkt umschließen. Es kann außerdem angenommen werden, dass näher liegende Punkte grundsätzlich auf eine bessere Approximation führen. Die Anforderung des Umschließens und der minimalen Fläche führen darauf, dass die besten neuen Punkte, diejenigen Punkte sind, welche die Nachbardreiecke des ersten Delauny Dreiecks sind. Jede Seite des Dreiecks ist Element eines weiteren Dreiecks. Dieses wird durch zwei Punkte aus dem ersten Dreieck, sowie einem neuen Punkt aufgespannt. Es werden daher insgesamt drei neue Punkte zur Approximation gefunden.

\begin{figure}[h]
	\centering
		\includegraphics[width=1.2\textwidth]{images/Voronoi5.jpg}
	\caption[Anwendung - Zusatzpunkte ]{Anwendung - Zusatzpunkte \cite{For15}}
	\label{fig:mehrPkt}
\end{figure}

Jedes der neu gewonnen Dreiecke hat zwei freiliegende Kanten. Es ergeben sich sechs ($3 \cdot 2 = 6$) neue Dreiecke mit bis zu sechs neuen Approximationspunkten. (Es kann vorkommen, dass ein neuer Punkt Element mehrerer Dreiecke ist und somit weniger als sechs neue Punkte gewonnen werden. Hierzu sind weitere Überlegungen nötig, da das gleichmäßige Umschließen nicht mehr vollständig gegeben ist. Es bleibt daher eine offene Frage, wie in diesem Fall am besten approximiert werden kann)


\subsection{Alternative Gewichtungsmethoden}
\label{subsec:gewichtung}
Nachdem in Unterabschnitt \ref{subsec:mehrpunkte} die relevanten Approximationspunkte bestimmt wurden, sollen nun weitere Gewichtungsmethoden diskutiert werden. Hierbei werden zwei unterschiedliche Möglichkeiten diskutiert. Es werden verschiedene Methoden zur Distanzermittlung genannt und außerdem wird kurz auf die gängigen Verfahren in den FEM hingewiesen. Stehen die Punkte zur Approximation fest, wird immer über ein arithmetisches Mittel approximiert. Der ungewichtete Mittelwert stellt das einfachste Mittel dar, weißt allerdings auch einen sehr großen Fehler auf. Deshalb wird dieses Mittel nicht weiter berücksichtigt.  Wie im Approximationsalgorithmus des Anwendungsbeispiels in Abschnitt \ref{sec:Anwendung Testfall} soll nun auch das gewichtete arithmetische Mittel genutzt werden. Die Gewichtsfunktionen beziehen sich hierbei auf das Ähnlichkeitsmaß. Im dimensionslosen Raum korrelieren Ähnlichkeitsmaß und Distanzmaß, daher kann nun über das Distanzmaß diskutiert werden. Einen allgemeinen Ansatz stellt hier die Minkowski-Norm dar.
\begin{equation}\label{f74}
d_{Minkowski} = \sqrt[r]{\sum_{j=1}^n|x_{p_j}-x_{i_j}|^p}
\end{equation}
wobei $r$ = Potenz der Wertepaardifferenzen, $x_p$ =  Approximationspunkt,\\ $x_i$ = Validierungspunkt $i$ und $j$ = Dimension. Als Sonderfälle lassen sich mit $r = 1$ das City-Block Distanzmaß
\begin{equation}\label{f75}
d_{City-Block} = \sqrt{\sum_{j=1}^n|x_{p_j}-x_{i_j}|^1}
\end{equation}
und mit $r = 2$ das bisher verwendete euklidische Distanzmaß ableiten.
\begin{equation}\label{f76}
d_{Euklid} = \sqrt[p]{\sum_{j=1}^n|x_{p_j}-x_{i_j}|^2}
\end{equation}
Als Alternative kann noch die Chebyshev-Distanz genannt werden. Hierbei wird die größte Einzelabweichung in einer Variablen (Dimension) als Distanzmaß genutzt.
\begin{equation}\label{f77}
d_{Chebyshev} = max|x_{p_j}-x_{i_j}|
\end{equation}
Zusätzlich zu Gewichtungsmethoden kann die numerische Problemlösung genannt werden. Aus der Diskretisierung über die Triangulation entsteht faktisch ein FEM-Problem. Das relevante Dreieck kann aus dem ($x,y$)-Raum (hier ($\Pi_2 , \Pi_3$)-Raum) in den ($\zeta, \eta$)-Raum transformiert werden. Es können zusätzliche Knoten eingeführt werden. Dies ermöglicht zusätzlich zu linearen auch quadratische Basisfunktionen und Ansätze höherer Ordnung zum lösen zu nutzen. Aufgrund der tiefe dieses Themas soll auf  \cite{Hah14} und \cite{MW09} verwiesen werden. Es ist ohne weitere tiefe Untersuchungen nicht möglich konkrete Aussagen über die Güte der genannten Distanzmaße und FEM-Lösungen zu treffen.
